name: CI

on:
  push:
    branches:
      - main
  pull_request:

jobs:
  # ============================================
  # Quality Checks (Linting, Formatting, Types)
  # ============================================
  quality:
    name: Quality Checks
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"

      - name: Install dependencies
        run: |
          pip install -e ".[dev]"

      # Ruff linting with GitHub annotations and SARIF output for SonarQube
      - name: Run ruff linting
        run: |
          ruff check src/ tests/ --output-format=github
          ruff check src/ tests/ --output-format=sarif -o ruff-results.sarif || true

      - name: Run ruff format check
        run: |
          ruff format --check src/ tests/

      # Mypy with SARIF output for SonarQube
      - name: Run mypy type checking
        run: |
          # Run mypy with JSON output and convert to SARIF
          mypy src/mayflower_sandbox --output=json > mypy-output.json 2>&1 || true
          python3 -c '
          import json, sys
          try:
              with open("mypy-output.json") as f:
                  lines = [json.loads(l) for l in f if l.strip()]
          except:
              lines = []
          sarif = {
              "$schema": "https://json.schemastore.org/sarif-2.1.0.json",
              "version": "2.1.0",
              "runs": [{
                  "tool": {"driver": {"name": "mypy", "version": "1.18", "rules": []}},
                  "results": []
              }]
          }
          rules_map = {}
          for item in lines:
              if item.get("severity") not in ("error", "warning", "note"): continue
              code = item.get("code", "unknown")
              if code not in rules_map:
                  rules_map[code] = len(sarif["runs"][0]["tool"]["driver"]["rules"])
                  sarif["runs"][0]["tool"]["driver"]["rules"].append({
                      "id": code, "name": code,
                      "shortDescription": {"text": f"mypy {code}"}
                  })
              sarif["runs"][0]["results"].append({
                  "ruleId": code, "ruleIndex": rules_map[code],
                  "level": {"error": "error", "warning": "warning"}.get(item.get("severity"), "note"),
                  "message": {"text": item.get("message", "")},
                  "locations": [{
                      "physicalLocation": {
                          "artifactLocation": {"uri": item.get("file", "")},
                          "region": {"startLine": item.get("line", 1), "startColumn": item.get("column", 1)}
                      }
                  }]
              })
          with open("mypy-results.sarif", "w") as f:
              json.dump(sarif, f, indent=2)
          print(f"Converted {len(lines)} mypy issues to SARIF")
          '
          # Also run with normal output for GitHub annotations
          mypy src/mayflower_sandbox || true

      # Bandit security scanner for Python
      # Exclude Pyodide sandbox helpers - they run in isolated WebAssembly, not host environment
      - name: Run Bandit security scan
        run: |
          bandit -r src/mayflower_sandbox --exclude src/mayflower_sandbox/helpers/document -f json -o bandit-results.json || true
          echo "Bandit scan complete"

      # ESLint for TypeScript
      - name: Run ESLint on TypeScript
        run: |
          npm init -y > /dev/null 2>&1
          npm install --save-dev eslint @typescript-eslint/parser @typescript-eslint/eslint-plugin typescript > /dev/null 2>&1
          cat > eslint.config.mjs << 'ESLINTCONFIG'
          import tsParser from "@typescript-eslint/parser";
          import tsPlugin from "@typescript-eslint/eslint-plugin";
          export default [{
            files: ["**/*.ts"],
            languageOptions: { parser: tsParser, parserOptions: { project: null } },
            plugins: { "@typescript-eslint": tsPlugin },
            rules: {
              ...tsPlugin.configs.recommended.rules,
              "@typescript-eslint/no-explicit-any": "warn",
              "@typescript-eslint/no-unused-vars": "warn"
            }
          }];
          ESLINTCONFIG
          npx eslint src/**/*.ts -f json -o eslint-results.json || true
          echo "ESLint scan complete"

      - name: Upload Ruff SARIF
        uses: actions/upload-artifact@v4
        with:
          name: ruff-sarif
          path: ruff-results.sarif
          retention-days: 7

      - name: Upload Mypy SARIF
        uses: actions/upload-artifact@v4
        with:
          name: mypy-sarif
          path: mypy-results.sarif
          retention-days: 7

      - name: Upload Bandit results
        uses: actions/upload-artifact@v4
        with:
          name: bandit-results
          path: bandit-results.json
          retention-days: 7

      - name: Upload ESLint results
        uses: actions/upload-artifact@v4
        with:
          name: eslint-results
          path: eslint-results.json
          retention-days: 7

  # ============================================
  # Unit Tests with Coverage
  # ============================================
  test:
    name: Tests
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_DB: mayflower_test
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"

      - name: Install Deno
        uses: denoland/setup-deno@v2
        with:
          deno-version: v2.x

      - name: Install dependencies
        run: |
          pip install -e ".[dev]"

      # Run TypeScript tests with Deno (with coverage)
      - name: Run TypeScript tests
        run: |
          deno test --allow-read --coverage=deno-coverage src/mayflower_sandbox/*_test.ts
          deno coverage deno-coverage --lcov > deno-coverage-raw.lcov
          # Convert absolute paths to paths relative to project root
          # Deno outputs: SF:/home/runner/_work/repo/repo/src/mayflower_sandbox/...
          # SonarQube expects paths relative to project root: SF:src/mayflower_sandbox/...
          echo "PWD is: $PWD"
          sed "s|SF:$PWD/|SF:|g" deno-coverage-raw.lcov > deno-coverage.lcov

          # Also convert LCOV to SonarQube generic coverage format (XML)
          # This provides a fallback in case LCOV parsing has issues
          python3 << 'LCOV_TO_XML'
          import re

          coverage_data = {}
          current_file = None

          with open('deno-coverage.lcov') as f:
              for line in f:
                  line = line.strip()
                  if line.startswith('SF:'):
                      current_file = line[3:]
                      coverage_data[current_file] = {}
                  elif line.startswith('DA:') and current_file:
                      parts = line[3:].split(',')
                      line_num = int(parts[0])
                      hit_count = int(parts[1])
                      coverage_data[current_file][line_num] = hit_count > 0

          # Generate XML
          xml = ['<coverage version="1">']
          for filepath, lines in coverage_data.items():
              xml.append(f'  <file path="{filepath}">')
              for line_num in sorted(lines.keys()):
                  covered = "true" if lines[line_num] else "false"
                  xml.append(f'    <lineToCover lineNumber="{line_num}" covered="{covered}"/>')
              xml.append('  </file>')
          xml.append('</coverage>')

          with open('deno-coverage.xml', 'w') as f:
              f.write('\n'.join(xml))

          print(f"Converted {len(coverage_data)} files to generic coverage XML")
          LCOV_TO_XML

          # Show coverage summary
          echo "=== TypeScript coverage ==="
          deno coverage deno-coverage
          echo ""
          echo "=== Raw LCOV SF paths ==="
          grep "^SF:" deno-coverage-raw.lcov
          echo ""
          echo "=== Converted LCOV SF paths (relative to project root) ==="
          grep "^SF:" deno-coverage.lcov
          echo ""
          echo "=== Generic coverage XML (first 20 lines) ==="
          head -20 deno-coverage.xml

      - name: Set up database schema
        env:
          PGPASSWORD: postgres
        run: |
          for f in migrations/*.sql; do
            echo "Running migration: $f"
            psql -h localhost -U postgres -d mayflower_test -f "$f"
          done

      # Run tests with JUnit XML and coverage XML output for SonarQube
      - name: Run tests
        env:
          POSTGRES_HOST: localhost
          POSTGRES_DB: mayflower_test
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_PORT: 5432
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          pytest -v -m "not slow" \
            --cov=src \
            --cov-report=term-missing \
            --cov-report=xml:coverage.xml \
            --junitxml=junit.xml

      - name: Upload test results
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: |
            junit.xml
            coverage.xml
            deno-coverage.lcov
            deno-coverage.xml
          retention-days: 7

  # ============================================
  # SonarQube Analysis
  # ============================================
  sonarqube:
    name: SonarQube Analysis
    runs-on: mayflower-k8s-runners
    needs: [quality, test]
    if: always()  # Run even if tests fail - we still want quality metrics

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Download test results
        uses: actions/download-artifact@v4
        with:
          name: test-results
          path: .
        continue-on-error: true

      - name: Download Ruff SARIF
        uses: actions/download-artifact@v4
        with:
          name: ruff-sarif
          path: .
        continue-on-error: true

      - name: Download Mypy SARIF
        uses: actions/download-artifact@v4
        with:
          name: mypy-sarif
          path: .
        continue-on-error: true

      - name: Download Bandit results
        uses: actions/download-artifact@v4
        with:
          name: bandit-results
          path: .
        continue-on-error: true

      - name: Download ESLint results
        uses: actions/download-artifact@v4
        with:
          name: eslint-results
          path: .
        continue-on-error: true

      # Debug: Verify coverage files
      - name: Debug coverage files
        run: |
          echo "=== Files in current directory ==="
          ls -la *.lcov *.xml 2>/dev/null || echo "No coverage files found"
          echo ""
          echo "=== Full deno-coverage.xml content ==="
          cat deno-coverage.xml 2>/dev/null || echo "deno-coverage.xml not found"
          echo ""
          echo "=== SF paths in LCOV file ==="
          grep "^SF:" deno-coverage.lcov 2>/dev/null || echo "No SF entries found"

      # Build dynamic SARIF paths (only include files that exist)
      - name: Prepare SARIF paths
        id: sarif
        run: |
          SARIF_FILES=""
          for f in ruff-results.sarif mypy-results.sarif; do
            if [ -f "$f" ]; then
              if [ -n "$SARIF_FILES" ]; then
                SARIF_FILES="$SARIF_FILES,$f"
              else
                SARIF_FILES="$f"
              fi
            fi
          done
          echo "paths=$SARIF_FILES" >> $GITHUB_OUTPUT
          echo "Found SARIF files: $SARIF_FILES"

      # Prepare external analyzer paths
      - name: Prepare external analyzer paths
        id: external
        run: |
          BANDIT_PATH=""
          ESLINT_PATH=""
          [ -f "bandit-results.json" ] && BANDIT_PATH="bandit-results.json"
          [ -f "eslint-results.json" ] && ESLINT_PATH="eslint-results.json"
          echo "bandit=$BANDIT_PATH" >> $GITHUB_OUTPUT
          echo "eslint=$ESLINT_PATH" >> $GITHUB_OUTPUT
          echo "Bandit: $BANDIT_PATH, ESLint: $ESLINT_PATH"

      # Debug: Show indexed files for TypeScript
      - name: Debug TypeScript file paths
        run: |
          echo "=== LCOV SF paths ==="
          grep "^SF:" deno-coverage.lcov || echo "No SF entries"
          echo ""
          echo "=== TypeScript files in src/ ==="
          find src -name "*.ts" -type f | sort
          echo ""
          echo "=== Checking tsconfig.json ==="
          cat tsconfig.json

      - name: SonarQube Scan
        uses: SonarSource/sonarqube-scan-action@v6
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}
        with:
          args: >
            -Dsonar.projectVersion=${{ github.sha }}
            -Dsonar.sarifReportPaths=${{ steps.sarif.outputs.paths }}
            -Dsonar.python.bandit.reportPaths=${{ steps.external.outputs.bandit }}
            -Dsonar.eslint.reportPaths=${{ steps.external.outputs.eslint }}
            -Dsonar.coverageReportPaths=deno-coverage.xml
            -Dsonar.verbose=true
