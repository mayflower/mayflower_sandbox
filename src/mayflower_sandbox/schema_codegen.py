"""
Schema Code Generator - Generate typed Python stubs from MCP tool schemas.

Generates Pydantic models and typed async wrapper functions from MCP tool
inputSchema definitions, providing IDE autocompletion and early validation.
"""

import json
import logging
import re
from typing import Any

from datamodel_code_generator import DataModelType, InputFileType, generate

logger = logging.getLogger(__name__)


def _to_pascal_case(name: str) -> str:
    """Convert tool_name to PascalCase for class names."""
    # Handle underscores and hyphens
    parts = re.split(r"[-_]", name)
    return "".join(word.capitalize() for word in parts)


def _to_snake_case(name: str) -> str:
    """Convert tool_name to snake_case for function names."""
    # Replace hyphens with underscores
    name = name.replace("-", "_")
    # Insert underscores before uppercase letters
    name = re.sub(r"([a-z0-9])([A-Z])", r"\1_\2", name)
    return name.lower()


def generate_model_for_tool(
    tool_name: str,
    input_schema: dict[str, Any],
) -> str | None:
    """
    Generate a Pydantic model class from a tool's inputSchema.

    Args:
        tool_name: Name of the MCP tool (e.g., "create_issue")
        input_schema: JSON Schema object for the tool's input

    Returns:
        Python code string for the Pydantic model, or None if generation fails
    """
    if not input_schema:
        return None

    # Ensure schema has a title for the class name
    schema = input_schema.copy()
    class_name = f"{_to_pascal_case(tool_name)}Args"
    schema["title"] = class_name

    try:
        import tempfile
        from pathlib import Path

        from datamodel_code_generator import PythonVersion

        # Generate Pydantic model using datamodel-code-generator
        # Must use temp file as output - generate() doesn't return string
        with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as f:
            output_path = Path(f.name)

        try:
            generate(
                json.dumps(schema),
                input_file_type=InputFileType.JsonSchema,
                output_model_type=DataModelType.PydanticV2BaseModel,
                output=output_path,
                use_standard_collections=True,
                use_union_operator=True,
                field_constraints=True,
                target_python_version=PythonVersion.PY_310,
            )
            return output_path.read_text()
        finally:
            output_path.unlink(missing_ok=True)
    except Exception as e:
        logger.warning(f"Failed to generate model for {tool_name}: {e}")
        return None


def _extract_class_from_model_code(model_code: str) -> tuple[str | None, set[str]]:
    """
    Extract class definition and imports from generated model code.

    Args:
        model_code: Generated Python code for a Pydantic model

    Returns:
        Tuple of (class_definition, imports_needed)
    """
    lines = model_code.split("\n")
    class_lines: list[str] = []
    imports_needed: set[str] = set()
    in_class = False

    for line in lines:
        if line.startswith("class "):
            in_class = True

        if in_class:
            class_lines.append(line)
        elif line.startswith("from ") or line.startswith("import "):
            imports_needed.add(line)

    class_def = "\n".join(class_lines) if class_lines else None
    return class_def, imports_needed


def _filter_extra_imports(imports_needed: set[str]) -> list[str]:
    """
    Filter imports to exclude ones already in module header.

    Args:
        imports_needed: Set of import statements

    Returns:
        List of extra imports not in standard header
    """
    extra_imports = []
    for imp in sorted(imports_needed):
        if "pydantic" not in imp and "typing" not in imp and "__future__" not in imp:
            extra_imports.append(imp)
    return extra_imports


def _build_module_header() -> list[str]:
    """Build standard module header."""
    return [
        '"""',
        "Auto-generated Pydantic models from MCP tool schemas.",
        "",
        "DO NOT EDIT - this file is generated by schema_codegen.py",
        '"""',
        "",
        "from __future__ import annotations",
        "",
        "from typing import Any, Optional",
        "",
        "from pydantic import BaseModel, Field",
        "",
    ]


def generate_models_module(
    tools: list[dict[str, Any]],
) -> str:
    """
    Generate a complete models.py module with all tool schemas.

    Args:
        tools: List of MCP tool definitions with 'name' and 'inputSchema'

    Returns:
        Complete Python module code string
    """
    models: list[str] = []
    all_imports: set[str] = set()

    for tool in tools:
        tool_name = tool.get("name", "")
        input_schema = tool.get("inputSchema", {})

        if not tool_name or not input_schema:
            continue

        model_code = generate_model_for_tool(tool_name, input_schema)
        if not model_code:
            continue

        class_def, imports = _extract_class_from_model_code(model_code)
        if class_def:
            models.append(class_def)
        all_imports.update(imports)

    # Build complete module
    module_parts = _build_module_header()

    # Add extra imports
    extra_imports = _filter_extra_imports(all_imports)
    if extra_imports:
        module_parts.extend(extra_imports)
        module_parts.append("")

    # Add all model classes
    module_parts.extend(models)

    return "\n".join(module_parts)


def _get_python_type(json_type: str | list, items: dict | None = None) -> str:
    """Convert JSON Schema type to Python type annotation."""
    type_map = {
        "string": "str",
        "integer": "int",
        "number": "float",
        "boolean": "bool",
        "null": "None",
        "object": "dict[str, Any]",
    }

    if isinstance(json_type, list):
        # Union type
        types = [_get_python_type(t, items) for t in json_type if t != "null"]
        if "null" in json_type:
            if len(types) == 1:
                return f"{types[0]} | None"
            return f"({' | '.join(types)}) | None"
        return " | ".join(types)

    if json_type == "array":
        if items:
            item_type = _get_python_type(items.get("type", "Any"), items.get("items"))
            return f"list[{item_type}]"
        return "list[Any]"

    return type_map.get(json_type, "Any")


def generate_typed_wrapper(
    server_name: str,
    tool: dict[str, Any],
) -> str:
    """
    Generate a typed async wrapper function for an MCP tool.

    Args:
        server_name: Name of the MCP server (e.g., "github")
        tool: MCP tool definition with 'name', 'description', and 'inputSchema'

    Returns:
        Python code string for the async wrapper function
    """
    tool_name = tool.get("name", "unknown")
    description = tool.get("description", "")
    input_schema = tool.get("inputSchema", {})

    func_name = _to_snake_case(tool_name)
    class_name = f"{_to_pascal_case(tool_name)}Args"

    # Parse schema properties
    properties = input_schema.get("properties", {})
    required = set(input_schema.get("required", []))

    # Build function signature
    params: list[str] = []
    param_docs: list[str] = []
    kwargs_assignment: list[str] = []

    for prop_name, prop_schema in properties.items():
        prop_type = _get_python_type(
            prop_schema.get("type", "Any"),
            prop_schema.get("items"),
        )
        prop_desc = prop_schema.get("description", "")

        if prop_name in required:
            params.append(f"{prop_name}: {prop_type}")
        else:
            params.append(f"{prop_name}: {prop_type} | None = None")

        if prop_desc:
            param_docs.append(f"        {prop_name}: {prop_desc}")

        kwargs_assignment.append(f"{prop_name}={prop_name}")

    # Build docstring
    docstring_parts = [f'    """{description}']
    if param_docs:
        docstring_parts.append("")
        docstring_parts.append("    Args:")
        docstring_parts.extend(param_docs)
    docstring_parts.append('    """')
    docstring = "\n".join(docstring_parts)

    # Build function
    params_str = ", ".join(params) if params else ""

    return f'''
async def {func_name}({params_str}) -> Any:
{docstring}
    from mayflower_mcp import call
    from .models import {class_name}

    validated = {class_name}({", ".join(kwargs_assignment)})
    payload = validated.model_dump(exclude_none=True)
    return await call("{server_name}", "{tool_name}", payload)
'''


def generate_tools_module(
    server_name: str,
    tools: list[dict[str, Any]],
) -> str:
    """
    Generate a complete tools.py module with typed wrapper functions.

    Args:
        server_name: Name of the MCP server
        tools: List of MCP tool definitions

    Returns:
        Complete Python module code string
    """
    module_parts = [
        '"""',
        f"Auto-generated typed wrappers for {server_name} MCP server tools.",
        "",
        "DO NOT EDIT - this file is generated by schema_codegen.py",
        '"""',
        "",
        "from __future__ import annotations",
        "",
        "from typing import Any",
        "",
    ]

    # Generate wrapper for each tool
    for tool in tools:
        if tool.get("name") and tool.get("inputSchema"):
            wrapper = generate_typed_wrapper(server_name, tool)
            module_parts.append(wrapper)

    return "\n".join(module_parts)


def generate_init_module(
    server_name: str,
    tools: list[dict[str, Any]],
) -> str:
    """
    Generate an __init__.py that exports all tools.

    Args:
        server_name: Name of the MCP server
        tools: List of MCP tool definitions

    Returns:
        Complete Python __init__.py code string
    """
    func_names = [
        _to_snake_case(tool.get("name", ""))
        for tool in tools
        if tool.get("name") and tool.get("inputSchema")
    ]

    exports = ", ".join(f'"{name}"' for name in func_names)
    imports = ", ".join(func_names)

    return f'''"""
{server_name} MCP server - auto-generated typed Python interface.

Usage:
    from servers.{server_name} import {func_names[0] if func_names else "tool_name"}

    result = await {func_names[0] if func_names else "tool_name"}(...)
"""

from .tools import {imports}

__all__ = [{exports}]
'''


def generate_server_package(
    server_name: str,
    tools: list[dict[str, Any]],
) -> dict[str, str]:
    """
    Generate a complete server package with models, tools, and init.

    Args:
        server_name: Name of the MCP server
        tools: List of MCP tool definitions

    Returns:
        Dict mapping filename to content:
        {
            "__init__.py": "...",
            "models.py": "...",
            "tools.py": "...",
            "schemas.json": "..."
        }
    """
    # Build schemas dict for storage
    schemas = {tool["name"]: tool.get("inputSchema", {}) for tool in tools if tool.get("name")}

    return {
        "__init__.py": generate_init_module(server_name, tools),
        "models.py": generate_models_module(tools),
        "tools.py": generate_tools_module(server_name, tools),
        "schemas.json": json.dumps(schemas, indent=2),
    }
